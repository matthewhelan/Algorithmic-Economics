{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fc30ed8"
      },
      "source": [
        "# CS 4501 Algorithmic Economics - Project 1\n",
        "\n",
        "**Note:** For each of the question, please add some print or graph drawing commands to show your results in a clear way and also necessary analyses and demonstrations to help people who are not in your group understand your logics and results.\n",
        "\n",
        "Bohan Wang, Arran Scaife and Matthew Whelan"
      ],
      "id": "9fc30ed8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcd94d38"
      },
      "source": [
        "## Part 1\n",
        "### Question 1\n",
        "Using a Jupyter notebook import the csv file as pandas dataframe."
      ],
      "id": "dcd94d38"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "428ba198",
        "outputId": "8705153f-a705-435c-92c9-36702a0c175f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Customer_ID 22625\n",
            "Number of SKU   5242\n",
            "        Unnamed: 0        Date  Customer_ID  Transaction_ID SKU_Category  \\\n",
            "156            157  02/01/2016            3              90          TW8   \n",
            "157            158  02/01/2016          427              91          R6E   \n",
            "158            159  02/01/2016          427              91          R6E   \n",
            "159            160  02/01/2016          427              91          Q4N   \n",
            "160            161  02/01/2016         3235              92          R6E   \n",
            "...            ...         ...          ...             ...          ...   \n",
            "128098      128099  31/12/2016        16860           64622          Q4N   \n",
            "128099      128100  31/12/2016        16860           64622          R6E   \n",
            "128100      128101  31/12/2016        16860           64622          R6E   \n",
            "128101      128102  31/12/2016        16860           64622          SFC   \n",
            "128091      128092  31/12/2016        17306           64616          C8Z   \n",
            "\n",
            "          SKU  Quantity  Sales_Amount  Week     Timestamp  \n",
            "156     WALAE       1.0          1.38     0  1.451693e+09  \n",
            "157     DLFQW       1.0          4.19     0  1.451693e+09  \n",
            "158     F90L2       1.0          2.31     0  1.451693e+09  \n",
            "159     LKDTY       1.0          8.69     0  1.451693e+09  \n",
            "160     DUWYY       1.0          4.19     0  1.451693e+09  \n",
            "...       ...       ...           ...   ...           ...  \n",
            "128098  MRE4J       1.0          3.41    53  1.483142e+09  \n",
            "128099  V6P7N       1.0          2.13    53  1.483142e+09  \n",
            "128100  F90L2       1.0          2.49    53  1.483142e+09  \n",
            "128101  AM6EH       1.0          2.86    53  1.483142e+09  \n",
            "128091  520UE       1.0          8.49    53  1.483142e+09  \n",
            "\n",
            "[131704 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv ('scanner_data.csv')\n",
        "#print (df)\n",
        "\n",
        "print(  \"Number of Customer_ID\",    len(pd.unique(df['Customer_ID']))  )\n",
        "print(  \"Number of SKU  \",    len(pd.unique(df['SKU']))  )\n",
        "date = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
        "week = [0]*len(date)\n",
        "timestamp = [0]*len(date)\n",
        "\n",
        "#print(df.isocalendar().week)\n",
        "\n",
        "for i in range(len(date)):\n",
        "  week[i] = (date[i].isocalendar()[1] + 1) % 54\n",
        "  timestamp[i] = date[i].timestamp()\n",
        "  \n",
        "#print((week[index] + 1) % 54)\n",
        "#print(date[index])\n",
        "df['Week'] = week\n",
        "df['Timestamp'] = timestamp\n",
        "\n",
        "df = df.sort_values(by=\"Timestamp\") #sorts\n",
        "print(df.iloc[1:131705])\n",
        "\n",
        "\n",
        "del week,date,timestamp\n",
        "#we print out the table of the data imported and note the number of unique Customer_IDs and unique SKUs\n"
      ],
      "id": "428ba198"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95ca3f70"
      },
      "source": [
        "### Question 2\n",
        "The fact that consumer does not purchase anything can be \n",
        "interpreted as that she chose an outside option. Given that the fact that she chose an outside option is not recorded in this dataset, argue how you would construct a proxi variable for the choice of an outside option. Add such a proxi variable to your dataframe. \n",
        "\n",
        "**Hint:** you can use information that some consumers do not appear in the data every week. "
      ],
      "id": "95ca3f70"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa33658f"
      },
      "source": [
        "**Please input your answer in this cell:*\n",
        "\n",
        "We have decided to first split the model into weeks so that each consumer is guarenteed to have at least 52 data points to train on (where each week has at minimum one transaction).\n",
        "Thus, we iterate through every week and mark which customers do not show up. We create empty transactions for them that week where we add our own SKU: \"not an option\" to represent an outside option being taken, as well as sales amounts of 0.00. We also add in the transaction the Customer_ID and the week. Thus, for every customer, we have empty transactions for every week they do not show up in our data (i.e. they took an outside option). \n"
      ],
      "id": "fa33658f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04e1c7b2"
      },
      "source": [
        "Add such a proxi variable to your dataframe. \n"
      ],
      "id": "04e1c7b2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47e81891"
      },
      "outputs": [],
      "source": [
        "#split table into weeks\n",
        "#create 3d array, first sorted by Week number, then by product SKU and customer ID (order of last 2 doesn't matter)\n",
        "#df = df[[]]\n",
        "#df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "#df = df.sort_values(by=\"Date\") #sorts\n",
        "#print(df['Quantity'][i])\n",
        " \n",
        "proxi = {} \n",
        " \n",
        "for i in range(len(df)):\n",
        "  inner = (df.loc[i,'SKU'], df.loc[i,'Customer_ID'])\n",
        "  q = df.loc[i,'Quantity']\n",
        "  try:\n",
        "    proxi[inner] += 1;\n",
        "  except KeyError:\n",
        "      proxi[inner] = 1;\n",
        "  #print(inner, proxi[inner])\n",
        "print(\"Proxi variable counting transactions:\")\n",
        "print(proxi)\n",
        "\n",
        "#  if inner in proxi.keys():\n",
        "#    proxi[inner] += 1\n",
        "#  else:\n",
        "#    proxi[inner] = 1"
      ],
      "id": "47e81891"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFtZsAlRoE2H"
      },
      "outputs": [],
      "source": [
        "#How many unique SKUs?\n",
        "skus = 0\n",
        "s = {}\n",
        "\n",
        "for k in range(len(df)):\n",
        "  try:\n",
        "    s[df.at[k,'SKU']] = s[df.at[k,'SKU']]\n",
        "  except KeyError:\n",
        "    s[df.at[k,'SKU']] = skus\n",
        "    skus+=1\n",
        "\n",
        "print(\"Unique SKUS:\", skus)\n",
        "\n",
        "#How many unique Customer IDs?\n",
        "\n",
        "cust = 0\n",
        "c = {}\n",
        "\n",
        "for k in range(len(df)):\n",
        "  try:\n",
        "    c[df.at[k,'Customer_ID']] = c[df.at[k,'Customer_ID']]\n",
        "  except KeyError:\n",
        "    c[df.at[k,'Customer_ID']] = cust\n",
        "    cust+=1\n",
        "\n",
        "print(\"Unique Customer IDs:\", cust)\n",
        "\n",
        "#How many unique Weeks?\n",
        "\n",
        "w = 0\n",
        "weeks = {}\n",
        "\n",
        "for k in range(len(df)):\n",
        "  try:\n",
        "    weeks[df.at[k,'Week']] = weeks[df.at[k,'Week']]\n",
        "  except KeyError:\n",
        "    weeks[df.at[k,'Week']] = w\n",
        "    w+=1\n",
        "\n",
        "print(\"Unique Weeks:\", w)"
      ],
      "id": "pFtZsAlRoE2H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that to simplify our runtime, we only run our analysis on the top most active customers. Here, we find a list of the top most active customers."
      ],
      "metadata": {
        "id": "sLiQoKEGZof8"
      },
      "id": "sLiQoKEGZof8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2VDZ3drxvMG"
      },
      "outputs": [],
      "source": [
        "#Determines a list of the 100 most active customers\n",
        "\n",
        "quantity_list = ['Customer_ID', 'quantity']\n",
        "\n",
        "quantity_df = pd.DataFrame(index=list(range(1, max(df['Customer_ID'])+1)), columns=quantity_list)\n",
        "#print(quantity_list)\n",
        "\n",
        "#defaults to empty, you can manually change by calling feature_df.at[CUSTOMER_ID, 'FEATURE_NAME'] = VALUE_TO_CHANGE_TO\n",
        "#example:\n",
        "#feature_df.at[1, 'Average Transaction Expense'] = 1\n",
        "\n",
        "\n",
        "#sorts df by customer_id\n",
        "df = df.sort_values(by=\"Customer_ID\")\n",
        "num_of_customers = max(df['Customer_ID'])\n",
        "\n",
        "#we iterate this is needed\n",
        "customer = 1 \n",
        "total_items_for_specific_customer = 0\n",
        "#print(df)\n",
        "\n",
        "#    print(\"Customer ID\", str(row[\"Customer_ID\"]))\n",
        "\n",
        "#Note that df is sorted by Customer_ID\n",
        "#print(df)\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  if row[\"Customer_ID\"] == customer:\n",
        "    total_items_for_specific_customer = total_items_for_specific_customer + row[\"Quantity\"] \n",
        "  #where we reach a new customer\n",
        "  elif not row[\"Customer_ID\"] == customer:\n",
        "    quantity_df.at[customer, 'Customer_ID'] = customer\n",
        "    quantity_df.at[customer, 'quantity'] = total_items_for_specific_customer\n",
        "\n",
        "\n",
        "    #reset total_items_for_specific_customer\n",
        "    total_items_for_specific_customer = row[\"Quantity\"]\n",
        "    customer = customer+1\n",
        "\n",
        "#case for very lastmost customer\n",
        "quantity_df.at[customer, 'Customer_ID'] = customer\n",
        "quantity_df.at[customer, 'quantity'] = total_items_for_specific_customer\n",
        "\n",
        "#now we sort quantity_df by quantity to get the 1000-most active customers\n",
        "quantity_df = quantity_df.sort_values(by = 'quantity', ascending=False)\n",
        "\n",
        "#print(quantity_df)\n",
        "\n",
        "#now, we can get a list of the 1000 most active customers\n",
        "top_cust_num = 100\n",
        "top_100_list = []\n",
        "count = 1\n",
        "for index, row in quantity_df.iterrows():\n",
        "  top_100_list.append(row['Customer_ID'])\n",
        "  count = count + 1\n",
        "  if count == (top_cust_num + 1):\n",
        "    break\n",
        "print(\"Top 100 most active customers: \",top_100_list)\n",
        "print(\"Number of top customers in list: \", len(top_100_list))"
      ],
      "id": "k2VDZ3drxvMG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then parse our dataframe of transactions so that only transactions involving the people in our most active list remain. "
      ],
      "metadata": {
        "id": "I-_7YZOBZwwH"
      },
      "id": "I-_7YZOBZwwH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7ocq8SNoIIo"
      },
      "outputs": [],
      "source": [
        "# Parse the data frame so that only transactions from the top 1000 active customers remain\n",
        "#list of indexes to drop\n",
        "labels_to_drop = []\n",
        "labels_dropped = 0\n",
        "for index, row in df.iterrows():\n",
        "  if not row['Customer_ID'] in top_100_list:\n",
        "    labels_to_drop.append(index)\n",
        "    labels_dropped += 1\n",
        "df=df.drop(labels=labels_to_drop, axis=0)\n",
        "print(df)\n",
        "print(labels_dropped, \" transactions removed\")"
      ],
      "id": "R7ocq8SNoIIo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we insert our proxi variable for an outside option. Over the week, we keep a list of the customers who did not show my starting with a list of all customers and crossing them off as we find transactions for the week. Thus, once the week is over, our remaining list contains all the customer_ids that did not show that week, meaning they took an outside option.\n",
        "\n",
        "Using those customer_ids from the list, we create empty transactions for them for the list to represent the no option being taken. We repeat this process for every week."
      ],
      "metadata": {
        "id": "FQz2Yrj0ajdz"
      },
      "id": "FQz2Yrj0ajdz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5J2oD7jUJ6C"
      },
      "outputs": [],
      "source": [
        "df = df.sort_values(\"Week\")\n",
        "df_copy = df\n",
        "#print(df.dtypes)\n",
        "#print(df)\n",
        "Nan = float('NaN')\n",
        "\n",
        "#This is just testing of how to make a new row and add it to the df dataframe\n",
        "#df2 = pd.DataFrame({'Unnamed: 0':[Nan],'Date':[Nan], 'Customer_ID': [0000], 'Transaction_ID':[Nan] ,'SKU_Category':[Nan],'SKU':['not an option'], 'Quantity':[Nan], 'Sales_Amount':[0.00], 'Week':[week], 'Timestamp': [Nan]})\n",
        "#print(df2)\n",
        "#df = pd.concat([df, df2], ignore_index = True, axis = 0)\n",
        "#print(df)\n",
        "\n",
        "\n",
        "#we have a list of all 1000 customers\n",
        "#print(df)\n",
        "number_of_dictionaries_prime = 100000\n",
        "lst_prime = [dict() for number in range(number_of_dictionaries_prime)]\n",
        "count_prime = 0\n",
        "top_100_list_copy = top_100_list.copy()\n",
        "#print(top_100_list_copy)\n",
        "week = 0\n",
        "#We iterate through each transaction and mark off if that customer made a transaction from our list\n",
        "for index, row in df.iterrows():\n",
        "  #if we are in the same week, we check if the customer_id is in the list or not\n",
        "  if row[\"Week\"] == week:\n",
        "      #remove customer_id if exists in list\n",
        "      if row[\"Customer_ID\"] in top_100_list_copy:\n",
        "        top_100_list_copy.remove(row[\"Customer_ID\"])\n",
        "      #otherwise, we do nothing and move on\n",
        "  \n",
        "  #we check if we have reached our final index of the original column. If so, we finalize our list for this last week\n",
        "\n",
        "  #This means we have reached a new week. Thus, we finalize our list for the previous week\n",
        "  elif not row[\"Week\"] == week:\n",
        "    #for every remaining customer_ID, appends a new row to df representing an outside option\n",
        "    for i in top_100_list_copy:\n",
        "      lst_prime[count_prime] = {'Unnamed: 0':Nan,'Date':Nan, 'Customer_ID': i, 'Transaction_ID':0 ,'SKU_Category':Nan,'SKU':'not an option', 'Quantity':0.0, 'Sales_Amount':0.00, 'Week':week, 'Timestamp': Nan}\n",
        "      count_prime += 1\n",
        "      #df2 = pd.DataFrame({'Unnamed: 0':[Nan],'Date':[Nan], 'Customer_ID': [i], 'Transaction_ID':[Nan] ,'SKU_Category':[Nan],'SKU':['not an option'], 'Quantity':[Nan], 'Sales_Amount':[0.00], 'Week':[week], 'Timestamp': [Nan]})\n",
        "      #df = pd.concat([df, df2], ignore_index = True, axis = 0)\n",
        "\n",
        "    #We reset the Customer_ID_list_weekly and add +1 to the week\n",
        "    top_100_list_copy = top_100_list.copy()\n",
        "    week += 1\n",
        "    if row[\"Customer_ID\"] in top_100_list_copy:\n",
        "        top_100_list_copy.remove(row[\"Customer_ID\"])\n",
        "\n",
        "#if it is the final week, we would reach here as our booleans don't catch it. So, we merely do the final week here\n",
        "for i in top_100_list_copy:\n",
        "  lst_prime[count_prime] = {'Unnamed: 0':Nan,'Date':Nan, 'Customer_ID': i, 'Transaction_ID':0 ,'SKU_Category':Nan,'SKU':'not an option', 'Quantity':0.0, 'Sales_Amount':0.00, 'Week':week, 'Timestamp': Nan}\n",
        "  #df2 = pd.DataFrame({'Unnamed: 0':[Nan],'Date':[Nan], 'Customer_ID': [i], 'Transaction_ID':[Nan] ,'SKU_Category':[Nan],'SKU':['not an option'], 'Quantity':[Nan], 'Sales_Amount':[0.00], 'Week':[week], 'Timestamp': [Nan]})\n",
        "  #df = pd.concat([df, df2], ignore_index = True, axis = 0)\n",
        "del lst_prime[count_prime:]\n",
        "df2 = pd.DataFrame(lst_prime, columns=df.columns.values.tolist())\n",
        "#print(df2)\n",
        "df = pd.concat([df,df2], ignore_index=True, axis=0)\n",
        "print(df)\n",
        "print(count_prime, \" empty transactions added to the dataset\")"
      ],
      "id": "z5J2oD7jUJ6C"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we split the transactions such that every transaction has quantity of 1. "
      ],
      "metadata": {
        "id": "76INwWiSb-W8"
      },
      "id": "76INwWiSb-W8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHo4saNylPDN"
      },
      "outputs": [],
      "source": [
        "# number_of_dictionaries = 10000000\n",
        "# lst = [dict() for number in range(number_of_dictionaries)]\n",
        "# count = 0\n",
        "# #we split up the multiple quantity orders into separate entries\n",
        "# for index, row in df.iterrows():\n",
        "#       #print(df.loc[index, 'Quantity'])\n",
        "#       if (df.loc[index, 'Quantity'] > 1):\n",
        "#         temp = df.loc[index, 'Quantity']\n",
        "#         df.loc[index, 'Quantity'] = 1\n",
        "#         for i in range(((int) (temp))-1):\n",
        "#           d = {'Unnamed: 0':df.loc[index, 'Unnamed: 0'],\n",
        "#                               'Date':df.loc[index, 'Date'], \n",
        "#                               'Customer_ID': df.loc[index, 'Customer_ID'], \n",
        "#                               'Transaction_ID':df.loc[index, 'Transaction_ID'] , \n",
        "#                               'SKU_Category': df.loc[index, 'SKU_Category'],\n",
        "#                               'SKU':df.loc[index, 'SKU'], 'Quantity':1.0, \n",
        "#                               'Sales_Amount':df.loc[index, 'Sales_Amount']/temp, \n",
        "#                               'Week': df.loc[index, 'Week'], \n",
        "#                               'Timestamp': df.loc[index, 'Timestamp']}\n",
        "          \n",
        "#           lst[count] = d\n",
        "#           #print(count)\n",
        "#           count+=1\n",
        "#         #if (count > 1000):\n",
        "#         #  break\n",
        "#           #df2 = pd.DataFrame(d)\n",
        "#           #df = pd.concat([df, df2], ignore_index = True, axis = 0)\n",
        "\n",
        "# del lst[count:]\n",
        "# df2 = pd.DataFrame(lst, columns=df.columns.values.tolist())\n",
        "# print(df2)\n",
        "# df = pd.concat([df,df2], ignore_index=True, axis=0)\n",
        "\n",
        "      #df2 = pd.DataFrame({'Unnamed: 0':[Nan],'Date':[Nan], 'Customer_ID': [i], 'Transaction_ID':[Nan] ,'SKU_Category':[Nan],'SKU':['not an option'], 'Quantity':[Nan], 'Sales_Amount':[0.00], 'Week':[week], 'Timestamp': [Nan]})\n",
        "      #df = pd.concat([df, df2], ignore_index = True, axis = 0)\n",
        "#print(df)\n",
        "\n",
        "#NOTES: Possible features\n",
        "#transaction history (times purchased previously for a given SKU)/Same with Category, average transaction price per SKU, "
      ],
      "id": "cHo4saNylPDN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a60b9ef"
      },
      "source": [
        "### Question 3\n",
        "Given that we do not have **explicit** consumer feature vectors $\\mathbf{x}^i = (x^i_1, \\cdots, x_k^i)$  in the data, discuss how you would construct such feature vectors for each consumer $i$ from the given data. Add your constructed characteristics to your dataframe. \n",
        "\n",
        "**Hint:** you can use transaction history and argue that past shopping patterns may give a good characterization for a given consumer."
      ],
      "id": "6a60b9ef"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bc09a47"
      },
      "source": [
        "**Please input your answer in this cell:**\n",
        "\n",
        "We attempt to extrapolate consumer feature vectors for each consumer from the data. We do so by sorting the dataframe by the customer ID (to make it easier to iterate through the list), iterating through the transaction list and calculating, and dynamically updating the necessary information to help extrapolate our variables. \n",
        "\n",
        "**Feature Variables:** \n",
        "\n",
        "We define our consumer-specific feature vector by the follwing features to a new data frame:\n",
        "\n",
        "\n",
        "*   Average Price Per Product - this is defined as the total spent by a consumer divided by the total items purchased by a consumer.\n",
        "\n",
        "*   Num of Unique Weeks Came - the number of weeks that have at least one transaction made by a consumer.\n",
        "\n",
        "*   Total Quantity of Items Bought - the sum of all of the quantities of items that a consumer has purchased.\n",
        "\n",
        "*   Unique Transactions - the total times a customer has visited the store (this does not include multiple purchases in one transaction)\n",
        "\n",
        "*   Average Weekly Frequency - the total times a consumer has visited the store divided by the number of unique weeks a customer comes to the store.\n",
        "\n",
        "*   Average Products Bought Per Visit - the cumulative amount of items purchased by a consumer divided by the cumulative amount of times a customer has came to the store.\n",
        "\n",
        "*   Average Expense Per Visit - the overall total spent by a consumer divided by the cumulative times a customer has came to the store.\n",
        "\n",
        "\n",
        "*   Min Week - the first week that a consumer makes a transaction.\n",
        "\n",
        "\n",
        "*   Max Week - the final week that a consumer makes a transaction.\n",
        "\n",
        "\n",
        "These features give a comprehensive view of the data pertinent to a given consumer. Specifically, they give insight to the consumer's behavior in regards to frequency shopped, how many products they buy when they do shop and how much they spend.\n",
        "\n",
        "\n"
      ],
      "id": "7bc09a47"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaoRqMZ90VsO"
      },
      "outputs": [],
      "source": [
        "# Here, we are assigning each SKU a unique number value, where 'not an option' = 0\n",
        "''' df = df.sort_values(by=\"SKU\")\n",
        "\n",
        "#SKU_List initialized to just 'not an option' to represent there being no outside option taken = 0\n",
        "SKU_List = ['not an option']\n",
        "for index, row in df.iterrows():\n",
        "  if not row['SKU'] == 'not an option':\n",
        "    if row[\"SKU\"] not in SKU_List:\n",
        "      SKU_List.append(row[\"SKU\"])\n",
        "num_list = list(range(0, len(SKU_List)))\n",
        "#print(num_list)\n",
        "\n",
        "sku_df = pd.DataFrame({'sku':SKU_List, 'num_index': num_list})\n",
        "print(sku_df) '''"
      ],
      "id": "QaoRqMZ90VsO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fed0c2a6"
      },
      "outputs": [],
      "source": [
        "#construct your new variable\n",
        "#df['feature 1'] = df.iloc[].sum(axis=1)\n",
        "\n",
        "#CHANGE THIS FEATURE_LIST TO ADD/REMOVE FEATURES\n",
        "#Features are defaulted to null unless changed\n",
        "feature_list = ['Average Price Per Product', 'Total Quantity of Items Bought', 'Num of Unique Weeks Came', 'Unique Transactions', 'Average Weekly Frequency', 'Average Products Bought Per Visit','Average Expense Per Visit','Min Week', 'Max Week']\n",
        "\n",
        "feature_df = pd.DataFrame(index=top_100_list, columns=feature_list)\n",
        "#print(feature_df)\n",
        "#defaults to empty, you can manually change by calling feature_df.at[CUSTOMER_ID, 'FEATURE_NAME'] = VALUE_TO_CHANGE_TO\n",
        "#example:\n",
        "#feature_df.at[1, 'Average Transaction Expense'] = 1\n",
        "\n",
        "\n",
        "#sorts df by customer_id\n",
        "df_copy = df_copy.sort_values(by=\"Customer_ID\")\n",
        "num_of_customers = max(df['Customer_ID'])\n",
        "\n",
        "#we iterate this is needed\n",
        "top_100_list.sort()\n",
        "print(type(top_100_list))\n",
        "print(top_100_list)\n",
        "x = 0\n",
        "customer = top_100_list[x]\n",
        "total_spent_for_specific_customer = 0.00\n",
        "total_items_for_specific_customer = 0\n",
        "total_transactions_for_specific_customer = 0\n",
        "\n",
        "unique_weeks_per_customer = []\n",
        "unique_transaction_ids_per_customer = []\n",
        "\n",
        "#for index, row in df.iterrows():\n",
        "#    print(\"Customer ID\", str(row[\"Customer_ID\"]))\n",
        "\n",
        "#Note that df is sorted by Customer_ID\n",
        "print(df_copy)\n",
        "\n",
        "for index, row in df_copy.iterrows():\n",
        "  #print(index)\n",
        "  #assume each transaction is of quantity 1...\n",
        "  #print(row[\"Sales_Amount\"])\n",
        "  if row[\"Customer_ID\"] == customer:\n",
        "    #check if the week in that transaction is already in unique_weeks_per_customer\n",
        "    if row[\"Week\"] not in unique_weeks_per_customer:\n",
        "      #if week is not already in, add it to the list\n",
        "      unique_weeks_per_customer.append(row[\"Week\"])\n",
        "\n",
        "    #check if that transaction is UNIQUE - already in unique_transaction_ids_per_customer\n",
        "    if row[\"Transaction_ID\"] not in unique_transaction_ids_per_customer and not 0:\n",
        "      #if transaction id is not in the list already, add it\n",
        "      unique_transaction_ids_per_customer.append(row[\"Transaction_ID\"])\n",
        "\n",
        "\n",
        "    total_spent_for_specific_customer = total_spent_for_specific_customer + row[\"Sales_Amount\"]\n",
        "    #print(total_spent_for_specific_customer)\n",
        "    total_items_for_specific_customer = total_items_for_specific_customer + row[\"Quantity\"]\n",
        "\n",
        "  if not row[\"Customer_ID\"] == customer:\n",
        "    num_of_unique_weeks_showed = len(unique_weeks_per_customer)\n",
        "    feature_df.at[customer, 'Num of Unique Weeks Came'] = num_of_unique_weeks_showed\n",
        "    feature_df.at[customer, 'Unique Transactions'] = len(unique_transaction_ids_per_customer)\n",
        "    feature_df.at[customer,'Average Weekly Frequency'] = (len(unique_transaction_ids_per_customer)/num_of_unique_weeks_showed)\n",
        "    feature_df.at[customer,'Min Week'] = min(unique_weeks_per_customer)\n",
        "    feature_df.at[customer,'Max Week'] = max(unique_weeks_per_customer)\n",
        "\n",
        "\n",
        "    #feature_df.at[customer,'Average Week'] = sum(unique_weeks_per_customer)/len(unique_weeks_per_customer)\n",
        "\n",
        "\n",
        "    if not total_items_for_specific_customer == 0:\n",
        "      avg_transaction_amount = total_spent_for_specific_customer/total_items_for_specific_customer\n",
        "      #print(avg_transaction_amount)\n",
        "      feature_df.at[customer, 'Average Price Per Product'] = avg_transaction_amount\n",
        "      feature_df.at[customer, 'Total Quantity of Items Bought'] = total_items_for_specific_customer\n",
        "\n",
        "    elif total_items_for_specific_customer == 0:\n",
        "      feature_df.at[customer, 'Average Price Per Product'] = 0.00\n",
        "      feature_df.at[customer, 'Total Quantity of Items Bought'] = total_items_for_specific_customer\n",
        "\n",
        "    if len(unique_transaction_ids_per_customer) == 0:\n",
        "        feature_df.at[customer, 'Average Products Bought Per Visit'] = 0\n",
        "        feature_df.at[customer, 'Average Expense Per Visit'] = 0.00\n",
        "    else:\n",
        "        feature_df.at[customer, 'Average Products Bought Per Visit'] = total_items_for_specific_customer/len(unique_transaction_ids_per_customer)\n",
        "        feature_df.at[customer, 'Average Expense Per Visit'] = total_spent_for_specific_customer/len(unique_transaction_ids_per_customer)\n",
        "    \n",
        "    #adds 1 to customer and resets total_spent_for_specific_customer\n",
        "    x = x +1\n",
        "    if x < 100:\n",
        "      customer = top_100_list[x]\n",
        "    total_spent_for_specific_customer = 0\n",
        "    total_items_for_specific_customer = 0\n",
        "    unique_weeks_per_customer = [row[\"Week\"]]\n",
        "    unique_transaction_ids_per_customer = []\n",
        "    if row[\"Customer_ID\"] == customer:\n",
        "      total_spent_for_specific_customer = row[\"Sales_Amount\"]\n",
        "      total_items_for_specific_customer = 1\n",
        "\n",
        "feature_df.at[customer, 'Num of Unique Weeks Came'] = len(unique_weeks_per_customer)\n",
        "feature_df.at[customer, 'Unique Transactions'] = len(unique_transaction_ids_per_customer)\n",
        "feature_df.at[customer,'Average Weekly Frequency'] = (len(unique_transaction_ids_per_customer)/num_of_unique_weeks_showed)\n",
        "feature_df.at[customer,'Min Week'] = min(unique_weeks_per_customer)\n",
        "feature_df.at[customer,'Max Week'] = max(unique_weeks_per_customer)\n",
        "\n",
        "\n",
        "#feature_df.at[customer,'Average Week'] = sum(unique_weeks_per_customer)/len(unique_weeks_per_customer)\n",
        "if total_items_for_specific_customer == 0:\n",
        "    feature_df.at[customer, 'Average Price Per Product'] = 0.00\n",
        "    feature_df.at[customer, 'Total Quantity of Items Bought'] = total_items_for_specific_customer\n",
        "else:\n",
        "  avg_transaction_amount = total_spent_for_specific_customer/total_items_for_specific_customer\n",
        "  feature_df.at[customer, 'Average Price Per Product'] = avg_transaction_amount\n",
        "  feature_df.at[customer, 'Total Quantity of Items Bought'] = total_items_for_specific_customer\n",
        "\n",
        "if len(unique_transaction_ids_per_customer) == 0:\n",
        "  feature_df.at[customer, 'Average Products Bought Per Visit'] = 0\n",
        "  feature_df.at[customer, 'Average Expense Per Visit'] = 0.00\n",
        "else:\n",
        "  feature_df.at[customer, 'Average Products Bought Per Visit'] = total_items_for_specific_customer/len(unique_transaction_ids_per_customer)\n",
        "  feature_df.at[customer, 'Average Expense Per Visit'] = total_spent_for_specific_customer/len(unique_transaction_ids_per_customer)\n",
        "\n",
        "print(feature_df) "
      ],
      "id": "fed0c2a6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIz8_2u1NefH"
      },
      "outputs": [],
      "source": [
        "print(df['Customer_ID'])"
      ],
      "id": "FIz8_2u1NefH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af0f1b62"
      },
      "outputs": [],
      "source": [
        "#restucture your data\n",
        "\n",
        "#df =  df[[]] \n",
        "\n"
      ],
      "id": "af0f1b62"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caa79024"
      },
      "source": [
        "### Question 4\n",
        "Produce the utility parameters $\\beta_{0j}, \\beta_{1j},\\cdots \\beta_{kj}$ and $\\alpha_j$ for every product $j$  by estimating a multinomial \n",
        "logit model from your constructed dataset."
      ],
      "id": "caa79024"
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating Matrix X\n",
        "all_columns = []\n",
        "row_column = []\n",
        "print(df)\n",
        "#iterate through all transactions, find the corresponding feature set to the row['Customer_ID'], in addition to the row[\"Sales_Amount\"]\n",
        "for index, row in df.iterrows():\n",
        "  for x in feature_df.columns:\n",
        "    row_column.append(feature_df.at[row[\"Customer_ID\"], x])\n",
        "  if row[\"Sales_Amount\"] == 0.00:\n",
        "    row_column.append(0.00)\n",
        "  else:\n",
        "    row_column.append(-row[\"Sales_Amount\"]/row[\"Quantity\"])\n",
        "  all_columns.append(row_column)\n",
        "  row_column = []\n",
        "X = np.array(all_columns)\n",
        "\n",
        "#X = X[:500]\n",
        "\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "UDjr4egCuOJd"
      },
      "id": "UDjr4egCuOJd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skus = 1\n",
        "sku_to_index = {'not an option': 0}\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  try:\n",
        "    sku_to_index[row[\"SKU\"]] = sku_to_index[row[\"SKU\"]]\n",
        "  except KeyError:\n",
        "    sku_to_index[row[\"SKU\"]] = skus\n",
        "    skus+=1\n",
        "''' for k in range(len(df)):\n",
        "  try:\n",
        "    sku_to_index[df.at[k,'SKU']] = sku_to_index[df.at[k,'SKU']]\n",
        "  except KeyError:\n",
        "    print(k)\n",
        "    sku_to_index[df.at[k,'SKU']] = skus\n",
        "    skus+=1 '''\n",
        "sku_to_price = {'not an option': 0}\n",
        "for index, row in df.iterrows():\n",
        "  if row[\"Quantity\"] != 0.0:\n",
        "    sku_to_price[row[\"SKU\"]] = row[\"Sales_Amount\"]/row[\"Quantity\"]\n",
        "\n",
        "index_to_sku = {v: k for k, v in sku_to_index.items()}\n",
        "print(\"Unique SKUS:\", skus)\n",
        "print(index_to_sku)\n",
        "print(len(sku_to_index))\n",
        "print(sku_to_price)\n",
        "print(len(df.SKU.unique()))"
      ],
      "metadata": {
        "id": "xHl5IJItPSqN"
      },
      "id": "xHl5IJItPSqN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = [0]*len(df)\n",
        "for i in range(len(df)):\n",
        "  y[i] = sku_to_index[df.at[i, 'SKU']]\n",
        "print(y)"
      ],
      "metadata": {
        "id": "XeXsYh9oPVVj"
      },
      "id": "XeXsYh9oPVVj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test , y_train , y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.0000000000000000000000000000000000000000000000000000001, random_state = 42)"
      ],
      "metadata": {
        "id": "wFl9gF5OsfAC"
      },
      "id": "wFl9gF5OsfAC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4c8924c"
      },
      "outputs": [],
      "source": [
        "#Hint: you can use sklearn.linear_model.LogisticRegression() to achieve an estimation\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(multi_class = 'multinomial', penalty='none', solver= 'newton-cg', verbose = 1, max_iter = 1, fit_intercept = True, n_jobs=8, warm_start=True)\n",
        "model.fit(X_train , y_train)\n"
      ],
      "id": "f4c8924c"
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "4EH87cvYsldS"
      },
      "id": "4EH87cvYsldS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The set of beta’s for the product 5: \",  model.coef_[5])\n",
        "print(model.coef_)\n",
        "print(model.coef_.shape)"
      ],
      "metadata": {
        "id": "8UTkIKd6smya"
      },
      "id": "8UTkIKd6smya",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.score(X_test, y_test)\n",
        "print(score)\n",
        "#print(1/1606)"
      ],
      "metadata": {
        "id": "HYdLXMMasoeO"
      },
      "id": "HYdLXMMasoeO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,p in zip(y_test, pred):\n",
        "  print(i,\":\", p, \"\\tSKU\", index_to_sku[p])"
      ],
      "metadata": {
        "id": "B7ORRle_sp3A"
      },
      "id": "B7ORRle_sp3A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53f8fd3a"
      },
      "source": [
        "# Part 2\n",
        "### Question 1\n",
        "Construct a multi-armed bandit algorithm such that\n",
        "\n",
        "1. It is randomly initialized at first and selects **one** product out of $j$ available products.\n",
        "2. It updates  $\\beta_{0j}, \\beta_{1j},\\cdots \\beta_{kj}$ and $\\alpha_j$  over  time by observing the utility $\\widehat{u}_{ij}$ of each product $j$ it selected in the past and selects new products\n"
      ],
      "id": "53f8fd3a"
    },
    {
      "cell_type": "code",
      "source": [
        "''' print(sku_df)\n",
        "import random\n",
        "random.seed(42)\n",
        "#we need to select a random SKU\n",
        "random_index = random.randint(0, skus)\n",
        "random_sku = sku_df.at[random_index, 'sku']\n",
        "print(random_sku) '''"
      ],
      "metadata": {
        "id": "RXRXcVststdm"
      },
      "id": "RXRXcVststdm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e04e4738"
      },
      "outputs": [],
      "source": [
        "#Hint: Try ridge regression on each arm separately,\n",
        "import random\n",
        "import math\n",
        "\n",
        "e = .5\n",
        "Beta_coef = np.ones(shape=model.coef_.shape)\n",
        "\n",
        "def decide(customer_idx):\n",
        "  explore = random.uniform(0,e)\n",
        "  cust_feat = feature_df.iloc[customer_idx].to_numpy()#feature_df[top_100_list[customer_idx]]\n",
        "  \n",
        "  if explore < e:\n",
        "    index = random.randint(0, len(model.coef_)-1)\n",
        "  else:\n",
        "    index = model.predict(cust_feat)\n",
        "  sku = index_to_sku[index]\n",
        "  Beta = model.coef_[index]\n",
        "  cust_feat = np.append(cust_feat, sku_to_price[sku])\n",
        "  utility = np.dot(cust_feat, Beta)\n",
        "  if math.isnan(utility):\n",
        "    print(cust_feat, \":\", Beta, \":\" ,utility)\n",
        "  return sku, Beta, utility\n",
        "''' cust_feat = feature_df.iloc[0].to_numpy()\n",
        "sku = index_to_sku[0]\n",
        "cust_feat = np.append(cust_feat, sku_to_price[sku])\n",
        "print(sku_to_price[sku])\n",
        "print(cust_feat) '''\n",
        "\n",
        "def update_parameter(sku, Beta, utility, N):\n",
        "  # keep track of number of times each product is selected\n",
        "  # keep track of eman for each product\n",
        "  index = sku_to_index[sku]\n",
        "  Beta_coef[index] = ((N+1)*Beta_coef[index] - Beta_coef[index] + Beta)/(N+1)\n",
        "  return"
      ],
      "id": "e04e4738"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59c55bb5"
      },
      "source": [
        "### Question 2\n",
        "\n",
        " Draw 1000 random consumers from your data. For each consumer,  run your online learning algorithm for 100 steps. Note that this is a simulation process --- i.e., your algorithm itself does not know $\\beta_{0j}, \\beta_{1j},\\cdots \\beta_{kj}$ and $\\alpha_j$, but can only observe the $\\widehat{u}_{ij}$ for any product $j$ that the algorithm pulled (i.e., purchased).     \n",
        " For each randomly picked consumer $i$, compute the difference $\\Delta_i$ between the  maximum utility $\\max_j\\widehat{u}_{ij}$ (i.e., consumer $i$'s  utility for her  favorite product) and the average utility that your algorithm\n",
        "achieved at the 100th step. Compute the average of $\\Delta_i$ over those 1000 consumers, and explain why there is such a difference.  "
      ],
      "id": "59c55bb5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6b3851e"
      },
      "outputs": [],
      "source": [
        "def rewards_difference(max_utility, average_utility):\n",
        "    return max_utility - average_utility\n",
        "\n",
        "def simulation():\n",
        "  total_delta_i = 0\n",
        "  for i in range(1000):\n",
        "    rand_cust = random.randint(0, top_cust_num-1)\n",
        "    max_utility = 0\n",
        "    average_utility = 0\n",
        "    for k in range(100):\n",
        "      rand_sku, rand_Beta, current_utility = decide(rand_cust)\n",
        "      if max_utility < current_utility:\n",
        "        max_utility = current_utility\n",
        "      average_utility += current_utility\n",
        "      update_parameter(rand_sku, rand_Beta, current_utility, k)\n",
        "    average_utility /= 100\n",
        "    delta_i = rewards_difference(max_utility, current_utility)\n",
        "    total_delta_i += delta_i\n",
        "  return total_delta_i / 1000"
      ],
      "id": "b6b3851e"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Avg delta i = \", simulation())\n",
        "print(\"Predicted Beta: \", Beta_coef)\n",
        "print(\"Actual Beta: \", model.coef_)"
      ],
      "metadata": {
        "id": "karylu2pszW_"
      },
      "id": "karylu2pszW_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04b91ba4"
      },
      "source": [
        "Explain why there is such a difference."
      ],
      "id": "04b91ba4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6239d3c1"
      },
      "source": [
        "**Please input your answer in this cell:**\n",
        "\n",
        "The avg maximum utility is achieved by the customer gaining utility from his/her favorite item to purchase (averaged per iteration). Thus, the avg maximum utility is achievable if and only if the customer purchases only his or her favorite item, as otherwise, it would be impossible to maximize utility.\n",
        "\n",
        "The average utility our algorithm achieved relies upon selecting a random product and doing either of two steps, the exploit step or the explore step (with probabilities 1-epsilon and epsilon respectively). During the exploit step, we choose the known item with the highest utility to the customer - note that this is only of the known items sets for the customer. During the explore step, we test the customer buying a randomized, other item. \n",
        "\n",
        "As a result, our algorithm relies on exploring unknown items (and exploiting, most likely, the items that are not the consumer's favorite) in order to find the avg utility provided at the 100th step. Meanwhile, the maximum avg utility is only possible if the consumer buys his/her favorite item (assuming constant utility provided per each purchase) for all iterations. Our algorithm requires purchasing other items, starting with a randomized SKU, meaning that we are guarenteeed to have a difference between the max avg utility and the avg utility calculated by our algorithm at the 100th step. "
      ],
      "id": "6239d3c1"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9_Cnnl-0tR1l"
      },
      "id": "9_Cnnl-0tR1l",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Project_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}